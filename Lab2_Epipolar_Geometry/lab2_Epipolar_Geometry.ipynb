{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab2 - Epipolar Geometry  \n",
    "\n",
    "## Objective\n",
    "\n",
    "The objective of this lab is to focus on the foundational elements of epipolar geometry. Using the provided functions in the `utils.py` file, you will complete the following utility functions in `utils_to_complete.py` based on your coursework:\n",
    "\n",
    "- `inverseHomogeneousMatrix()`\n",
    "- `multiplyHomogeneousMatrix()`\n",
    "- `skew()`\n",
    "\n",
    "![Figure 1](../assets/lab2/fig1.png)\n",
    "\n",
    "Consider a stereoscopic system providing two images, $I_1$  and $I_2$. The camera calibration is known. We will assume that, initially, the calibration matrix is given by:\n",
    "\n",
    "$$\\mathbf{K} =\n",
    "\\begin{pmatrix}\n",
    "800 & 0 & 200 \\\\\n",
    "0 & 800 & 150 \\\\\n",
    "0 & 0 & 1 \\\\\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "**Question 1**: What do the values in matrix $K$ represent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answear:**\n",
    "This matrix represents the **intrinsic parameters** of the camera. Specifically:\n",
    "- The entries $K[0,0] = 800$ and $K[1,1] = 800$ are the **focal lengths** in the $x$ and $y$ directions, respectively.\n",
    "- The values $K[0,2] = 200$ and $K[1,2] = 150$ represent the coordinates of the **principal point** (the image center) in the $x$ and $y$ directions, respectively.\n",
    "- The $1$ at $K[2,2]$ is a **scaling factor**, often set to 1 in homogeneous coordinates.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that camera $c2$ is positioned at the location defined by ${}^{c2}T_w$ (see Figure 2):\n",
    "\n",
    "$$\n",
    "{}^{c2}T_w =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & 0 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 2 \\\\\n",
    "0 & 0 & 0 & 1 \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "![Figure 2](../assets/lab2/fig2.png)\n",
    "\n",
    "#### Case 1: Camera $c_1$ is positioned 10 cm to the left of $c_2$\n",
    "\n",
    "**Question 2:** Provide the matrix ${}^{c1}T_w$. Using the provided code skeleton, complete the matrix ${}^{c1}T_w$.\n",
    "\n",
    "**Answear:**\n",
    "Since camera $c_1$ is positioned 10 cm (or 0.1 meters) to the left of $c_2$, the transformation matrix ${}^{c1}T_w$ will reflect this translation along the $x$-axis. Assuming no rotation, the matrix ${}^{c1}T_w$ is:\n",
    "\n",
    "$$\n",
    "{}^{c1}T_w =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & -0.1 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 2 \\\\\n",
    "0 & 0 & 0 & 1 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In this matrix:\n",
    "\n",
    "- The $0.$ in the $(1, 4)$ position indicates a 10 cm leftward translation of $c_1$ relative to $c_2$ along the $x$-axis.\n",
    "- The $2$ in the $(3, 4)$ position represents the $z$-axis translation of both cameras (since they are both positioned 2 units from the world origin along $z$).\n",
    "\n",
    "**Question 3:** What is this type of system called, and can you elaborate?\n",
    "\n",
    "*We aim to facilitate point matching between the two images. To do this, we will represent the geometric location of a point $x_1$ in image $I_1$, where its corresponding point $x_2$ in $I_2$ might be located.*\n",
    "\n",
    "**Question 4:** Characterize this location. Calculate its equation. In your report, provide the coordinates of points $x_1$ for the points $x_2$ at (100, 100) and (50, 75).\n",
    "\n",
    "**Question 5:** Display the points $x_2$ in $I_2$ and the previously calculated locations in $I_1$. Verify that the expected result is achieved and provide the obtained image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 2: Provide the matrix ${}^{c1}T_w$\n",
    "\n",
    "Since camera $c_1$ is positioned 10 cm (or 0.1 meters) to the left of $c_2$, the transformation matrix ${}^{c1}T_w$ will reflect this translation along the $x$-axis. Assuming no rotation, the matrix ${}^{c1}T_w$ is:\n",
    "\n",
    "$$\n",
    "{}^{c1}T_w =\n",
    "\\begin{pmatrix}\n",
    "1 & 0 & 0 & -0.1 \\\\\n",
    "0 & 1 & 0 & 0 \\\\\n",
    "0 & 0 & 1 & 2 \\\\\n",
    "0 & 0 & 0 & 1 \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "In this matrix:\n",
    "\n",
    "- The $0.$ in the $(1, 4)$ position indicates a 10 cm leftward translation of $c_1$ relative to $c_2$ along the $x$-axis.\n",
    "- The $2$ in the $(3, 4)$ position represents the $z$-axis translation of both cameras (since they are both positioned 2 units from the world origin along $z$).\n",
    "\n",
    "#### Question 3: What is this type of system called, and can you elaborate?\n",
    "\n",
    "This type of system is called a **stereo camera system** or a **stereoscopic vision system**.\n",
    "\n",
    "In a stereo camera system, two cameras are positioned at a known baseline distance apart, capturing two slightly different perspectives of the same scene. By analyzing the disparity between the two images (the difference in positions of corresponding points in each image), we can extract depth information, effectively estimating the 3D structure of the scene.\n",
    "\n",
    "Key features of a stereo camera system:\n",
    "\n",
    "- **Epipolar Geometry**: Each point in one image corresponds to a line (called the epipolar line) in the other image. This allows us to constrain the search for matching points to a 1D search along the epipolar lines, making disparity calculation more efficient.\n",
    "- **Depth Perception**: The system uses disparity (the horizontal offset between corresponding points in the left and right images) to compute depth. Closer objects have higher disparity, while farther objects have lower disparity.\n",
    "- **Applications**: Stereo vision is widely used in applications like autonomous driving, 3D reconstruction, robot navigation, and augmented reality.\n",
    "\n",
    "A stereo system configuration like this is foundational in computer vision, as it mimics the way human binocular vision perceives depth.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 2: Now position camera $c_1$ 20 $cm$ in front of $c_2$.\n",
    "\n",
    "**Question 6:** Provide the new matrix ${}^{c1}T_w$.\n",
    "\n",
    "\n",
    "**Question 7:** What is the position of the epipole?\n",
    "\n",
    "\n",
    "**Question 8:** Redo questions 4 and 5 for this new position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case 3: Now position camera $c1$ at ${}^{c1}T_w$ such that the translation is (0.1, 0, 1.9) and the rotation in degrees is (5, 5, 5), using the minimal representation angle-axis (also called theta-u).\n",
    "\n",
    "**Question 9** Provide the new matrix ${}^{c1}T_w$.\n",
    "\n",
    "\n",
    "**Question 10** Provide the new position of the epipoles.\n",
    "\n",
    "\n",
    "**Question 11** Redo questions 4 and 5 for this new position."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
